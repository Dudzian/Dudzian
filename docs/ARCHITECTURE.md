# Architektura bot_core

## Przegląd systemu

`bot_core` to modularna platforma do budowania i uruchamiania strategii krypto zgodna z etapem "foundation" opisanym w `docs/architecture/phase1_foundation.md`. Cały pipeline operacyjny działa **obowiązkowo w trybie demo/paper** do momentu przejścia pełnego cyklu bezpieczeństwa i zgodności. Dopiero po pozytywnym audycie kodu, potwierdzeniu kontroli ryzyka i podpisaniu akceptacji przez compliance możliwe jest przejście do środowiska LIVE.  Dziedziczny pakiet `KryptoLowca` pozostaje wyłącznie warstwą kompatybilności – nowe moduły i integracje powinny korzystać z przestrzeni nazw `bot_core.*` (np. `bot_core.ai.legacy_models`).

Przepływ danych przebiega następująco:

1. Warstwa strategii (lifecycle `prepare` → `handle_market_data` → `generate_signal`) działa na danych dostarczonych przez `bot_core/data`.
2. Wygenerowane sygnały trafiają do `bot_core/risk`, gdzie przechodzą weryfikację profili ryzyka oraz limitów ekspozycji.
3. Zatwierdzone sygnały są przekazywane do `bot_core/execution`, które realizuje zlecenia przy wsparciu adapterów z `bot_core/exchanges`.
4. Całość nadzoruje `bot_core/runtime`, łączące konfigurację, zarządzanie środowiskami i raportowanie alertów z `bot_core/alerts`.

## Proces demo → paper → live

Proces przejścia środowisk jest sekwencyjny i wymusza blokady bezpieczeństwa na każdym etapie:

- **Demo/Testnet:** domyślny tryb uruchomieniowy. `StrategyContext.require_demo_mode` blokuje wykonanie w środowisku innym niż demo, dopóki nie zostaną spełnione wymagania bezpieczeństwa.
- **Paper:** po udokumentowanych wynikach testów demo pipeline przechodzi w tryb paper trading. `bot_core/runtime.bootstrap_environment` weryfikuje konfigurację (`core.yaml`), podpisane poświadczenia, kanały alertów i profile ryzyka przed startem, a `KryptoLowca.runtime.bootstrap.bootstrap_frontend_services` dostarcza frontom (GUI, dashboard, launcher AutoTradera) wspólny `ExchangeManager`, `LiveExecutionRouter`, `MultiExchangeAccountManager` i `MarketIntelAggregator`.
- **Live:** aktywacja możliwa wyłącznie po przedstawieniu raportów z testów paper, przeglądu kodu bezpieczeństwa (`bot_core/security`) oraz zatwierdzenia compliance. `bot_core/execution` korzysta wówczas z adapterów `live`, włączane są rozszerzone alerty (kanały krytyczne + throttling) oraz automatyczne eskalacje do zespołu bezpieczeństwa.

Każdy etap wymaga aktualnych podpisów KYC/AML, potwierdzenia limitów w `RiskProfile` i rejestrowania zdarzeń audytowych. Przejście na wyższy poziom bez kompletu dokumentacji jest blokowane przez `runtime` (flagi `require_demo_mode`, `compliance_confirmed`) i walidację konfiguracji.

## Moduły `bot_core`

### `bot_core/exchanges`

Adaptery giełdowe (`BinanceSpotAdapter`, `BinanceFuturesAdapter`, `KrakenSpotAdapter`, `KrakenFuturesAdapter`, `ZondaSpotAdapter`) rozdzielają środowiska `demo`/`paper`/`live`, kontrolują uprawnienia (`read`/`trade`) i egzekwują podpisy HMAC wymagane przez API. Każdy adapter mapuje odpowiedzi na wspólne struktury (`AccountSnapshot`, `OrderStatus`) oraz obsługuje streaming danych, retry i walidację limitów notional.

### `bot_core/data`

Warstwa danych obejmuje `PublicAPIDataSource`, `CachedOHLCVSource` i usługi backfillu. Moduł pracuje dwuwarstwowo:

1. **Parquet jako źródło prawdy** – backfill zapisuje świeczki OHLCV do plików partycjonowanych według `exchange/symbol/granularity/year/month`. Format kolumnowy zapewnia dobrą kompresję, szybkie skany dla backtestów i łatwą integrację z Pandas/Polars.
2. **Manifest w SQLite** – lekka baza (`SQLiteCacheStorage`) przechowuje indeks metadanych (zakresy czasowe, wersje paczek, stany backfillu). Dzięki temu runtime odnajduje właściwe segmenty Parquet bez konieczności wczytywania wszystkich plików.

Źródła normalizują świeczki do UTC, deduplikują zapisy i stosują kontrolowany backoff, aby nie przekraczać limitów publicznych API giełd. Dane są indeksowane per środowisko i giełdę, co umożliwia równoległe testy demo/paper oraz szybkie odtwarzanie historii na potrzeby kontroli ryzyka.

### `bot_core/risk`

Moduł ryzyka (`RiskProfile`, `ThresholdRiskEngine`, `RiskRepository`) wymusza limity dziennych strat, liczbę pozycji, maksymalną ekspozycję per instrument i hard-stop drawdown. Silnik resetuje limity w UTC, blokuje sygnały przekraczające polityki, eskaluje incydenty do alertów oraz aktywuje tryb awaryjny po przekroczeniu progów ochronnych. Profile konfiguruje się w `config/core.yaml`, a walidacja odbywa się w runtime. Trwałość zapewnia `FileRiskRepository`, które zapisuje stan profilu w katalogu `var/data/<środowisko>/risk_state`, dzięki czemu restart aplikacji nie zdejmuje blokad bezpieczeństwa ani limitów dziennych.

### `bot_core/execution`

`ExecutionService` i `ExecutionContext` zamieniają zatwierdzone sygnały na zlecenia, uwzględniając prowizje, poślizg i zasady retry/backoff (`RetryPolicy`). `PaperTradingExecutionService` symuluje fill'e, zapisuje dziennik audytowy (zarówno w pamięci, jak i w trwałych plikach JSONL z rotacją wg polityki retencji) i dostarcza metryki do alertów. W trybie live usługa współpracuje z adapterami giełd z segmentu `live` oraz wymaga potwierdzonych uprawnień tradingowych.

### `bot_core/reporting`

Moduł raportowania buduje archiwa dziennego blottera z symulatora paper tradingu. Funkcja `generate_daily_paper_report` filtruje wpisy `PaperTradingExecutionService` i zdarzenia `TradingDecisionJournal` po strefie czasowej środowiska, a następnie zapisuje je jako `ledger.csv`, `decisions.jsonl` oraz `summary.json` w katalogu danych środowiska (domyślna retencja 24 miesiące). Archiwa są przygotowane pod dalsze podpisy kryptograficzne oraz pakowanie do zaszyfrowanych paczek w kolejnych etapach, dzięki czemu proces compliance otrzymuje gotowy pakiet audytowy.

### `bot_core/alerts`

`AlertRouter`, `AlertChannel` i `FileAlertAuditLog` obsługują powiadomienia (Telegram, e-mail, SMS, Signal, WhatsApp, Messenger) z kontrolą throttlingu i pełnym audytem zdarzeń (`channel="__suppressed__"` dla zdławionych komunikatów). Warstwa SMS jest modułowa: na starcie korzystamy z lokalnych operatorów (Orange Polska jako referencyjny, następnie inni dostawcy w PL i IS), a globalny agregator (Twilio/Vonage/MessageBird) działa jako fallback ciągłości działania. Alerty są elementem procesów bezpieczeństwa – incydenty krytyczne muszą zostać potwierdzone i przekazane do zespołu bezpieczeństwa w ciągu 24h.

`TradingDecisionJournal` w `bot_core/runtime/journal.py` uzupełnia audyt o ścieżkę decyzyjną strategii. `JsonlTradingDecisionJournal` zapisuje zdarzenia `signal_received`, `risk_rejected`, `risk_adjusted`, `order_submitted`, `order_executed` (oraz błędy) w plikach JSONL z retencją zgodną z polityką compliance (domyślnie 24 miesiące). `TradingController` automatycznie rejestruje powody odrzuceń, rekomendowane korekty wielkości, identyfikatory zleceń i koszty egzekucji, dzięki czemu raporty KYC/AML mogą odtworzyć pełny kontekst decyzji.

### `bot_core/runtime`

`bootstrap_environment` integruje konfigurację (`load_core_config`), adaptery giełdowe, profile ryzyka, alerty i manager sekretów w `BootstrapContext`. Runtime odpowiada za sekwencjonowanie przejść demo → paper → live, walidację flag compliance, rejestrację kontrolnych checklist oraz inicjalizację repozytoriów danych. Mechanizmy ochronne blokują start środowiska, jeśli brakuje kluczy API, audytów lub aktualnych podpisów regulacyjnych.  Wspólnym źródłem prawdy dla ustawień operacyjnych jest plik `config/runtime.yaml`, ładowany przez `load_runtime_app_config` (sekcje: `ai`, `trading`, `risk`, `licensing`, `ui`).  Uzupełniający `KryptoLowca.runtime.bootstrap.bootstrap_frontend_services` udostępnia desktopowym frontom spójny `ExchangeManager`, `LiveExecutionRouter`, `MultiExchangeAccountManager` i `MarketIntelAggregator`, dzięki czemu GUI i dashboard używają tych samych usług egzekucji oraz danych wywiadu rynkowego.

### `bot_core/security`

`SecretManager` i `KeyringSecretStorage` przechowują poświadczenia poza repozytorium, rozdzielając klucze `read` i `trade` dla każdego środowiska. Moduł implementuje rotację kluczy co 90 dni (z natychmiastową wymianą po zmianie uprawnień lub incydencie), walidację środowisk (paper/live/testnet) oraz integruje się z politykami IP allowlist. Klucze przechowujemy natywnie (Windows Credential Manager, macOS Keychain, GNOME Keyring/zaszyfrowany magazyn `age` w trybie headless). Wszystkie operacje są logowane i dostępne w dziennikach audytu wykorzystywanych przez compliance.

Nowy moduł `security.rotation` wprowadza rejestr rotacji zapisany w pliku `security/rotation_log.json` w katalogu danych środowiska. Klasa `RotationRegistry` pozwala oznaczać datę wymiany klucza i wyliczać ile dni pozostało do kolejnej rotacji, a skrypt `python scripts/check_key_rotation.py` raportuje środowiska zbliżające się do terminu oraz – opcjonalnie – zapisuje nową datę po wykonaniu procedury „bez-downtime”. Dzięki temu polityka 90‑dniowej rotacji ma techniczne wsparcie, a status każdego wpisu jest łatwy do audytowania.

Moduł `bot_core/security/profiles.py` oraz powiązany mostek CLI `bot_core/security/ui_bridge.py` udostępniają lekkie API do zarządzania profilami użytkowników i aktywną licencją OEM z poziomu aplikacji Qt. Dane przechowywane są w `config/user_profiles.json`, a każda operacja aktualizacji zapisuje wpis JSONL w `logs/security_admin.log`. UI otrzymało dedykowany dialog administracyjny pozwalający przeglądać licencję, przydzielać oraz usuwać profile RBAC (`metrics.read`/`metrics.write`) i synchronizować się z modułem bezpieczeństwa bez ręcznej edycji plików.

### `bot_core/observability`

 Telemetria UI została zintegrowana z eksporterem Prometheusa (`bot_core/observability/ui_metrics.py`) oraz rozszerzonym serwisem gRPC (`bot_core/runtime/metrics_service.py`). Każdy `MetricsSnapshot` aktualizuje metryki (`bot_ui_fps`, `bot_ui_overlay_active`, histogram janku itp.) i trafia do `UiTelemetryAlertSink`, który zapisuje zdarzenia w `logs/ui_telemetry_alerts.jsonl` oraz wysyła alerty przez `AlertRouter`. Eksporter promuje również kontekst ekranów – `bot_ui_screen_refresh_hz`, `bot_ui_screen_device_pixel_ratio` oraz `bot_ui_screen_resolution_px{dimension="width|height"}` – dzięki czemu dashboard Prometheus może korelować spadki FPS z konkretnymi konfiguracjami monitorów. Jeżeli UI nadaje tag (`notes.tag`) do swoich snapshotów, eksporter duplikuje główne metryki z etykietą `tag`, a sink alertów dołącza ją do kontekstu i wpisów JSONL, co pozwala filtrować incydenty według stanowisk lub środowisk (np. `desk-a`, `staging`). Dodatkowo eksporter utrzymuje wskaźniki aktywności tagów (`bot_ui_tag_active{tag="..."}`, `bot_ui_tag_active_count`, `bot_ui_tag_last_seen_seconds`) i wygasza je po domyślnie pięciominutowej bezczynności, dzięki czemu w grafanach widać zarówno bieżącą liczbę aktywnych stanowisk, jak i ostatni heartbeat z każdego tagu. Wraz z tym pojawiły się lustrzane wskaźniki nieaktywności (`bot_ui_tag_inactive{tag="..."}`, `bot_ui_tag_inactive_count`, `bot_ui_tag_inactive_age_seconds`), które pokazują, ile czasu minęło od ostatniej próbki oraz automatycznie resetują się po usunięciu przeterminowanego tagu – operator natychmiast widzi, które stanowiska są offline i od jak dawna. Serwer metryk potrafi obsłużyć TLS/mTLS, weryfikuje tokeny RBAC (scope `metrics.write`) i udostępnia dane dla UI, Prometheusa oraz pipeline'ów operacyjnych. Dzięki temu panel administratorski może jednocześnie monitorować kondycję interfejsu i reagować na ostrzeżenia o spadku FPS lub przekroczeniu budżetu nakładek. Dodatkowo `UiTelemetryAlertSink` śledzi teraz stan bufora retry – gdy backlog przekroczy konfigurowalny próg pojawia się ostrzeżenie „retry backlog”, a powrót poniżej progu skutkuje alertem informacyjnym. Eksporter metryk wzbogacono o `bot_ui_retry_incident_active`, `bot_ui_retry_incident_age_seconds`, `bot_ui_retry_incident_started_at_seconds` i histogram `bot_ui_retry_incident_duration_seconds`, co pozwala odczytać czas rozpoczęcia incydentu i jego łączny czas trwania bezpośrednio w Prometheusie. W analogiczny sposób śledzone są teraz incydenty janku – `bot_ui_jank_incident_active`, `bot_ui_jank_incident_age_seconds`, `bot_ui_jank_incident_started_at_seconds`, histogram `bot_ui_jank_incident_duration_seconds` oraz liczniki `bot_ui_jank_incidents_total` (globalnie i per tag) aktualizują się przy pierwszym spike'u i wygaszają po okresie ciszy, dzięki czemu operator widzi zarówno czas trwania anomalii, jak i to, które stanowiska wygenerowały ostrzeżenie. Każda próbka zwiększa licznik `bot_ui_snapshots_total`, aktualizuje znacznik `bot_ui_snapshot_generated_at_seconds`, wyznacza opóźnienie dostarczenia (`bot_ui_snapshot_delivery_latency_seconds`) oraz odstępy między kolejnymi próbkami (`bot_ui_snapshot_gap_seconds` i histogram `bot_ui_snapshot_gap_duration_seconds`), co pozwala łatwo wykryć braki heartbeatów i zdiagnozować problemy sieciowe zanim zagrożą stabilności panelu.

Eksporter rejestruje także wydajność UI wprost z pól snapshotu. Gauge `bot_ui_event_to_frame_p95_ms` oraz histogram `bot_ui_event_to_frame_p95_ms_distribution` pokazują, ile czasu (p95) upływa pomiędzy zdarzeniem a wyrenderowaniem klatki, a wartości z danej stacji roboczej są dodatkowo etykietowane `tag`. Stan zasobów procesu publikujemy poprzez `bot_ui_cpu_utilization_percent`, `bot_ui_gpu_utilization_percent`, `bot_ui_ram_usage_megabytes`, `bot_ui_dropped_frames_total` oraz `bot_ui_processed_messages_per_second`, dzięki czemu dashboard Prometheusa od razu ujawnia przegrzewające się stanowiska, aplikacje zajmujące zbyt dużo pamięci lub przetwarzające nietypowo mało komunikatów.

Na bazie tych samych próbek eksporter prowadzi linię czasu incydentów wydajnościowych. Gauge `bot_ui_performance_metric_state{metric="..."}` przyjmuje wartości 0/1/2 (OK/warning/critical), a liczniki `bot_ui_performance_severity_transitions_total{metric="...",state="warning|critical|recovered",reason="..."}` dokumentują eskalacje (`promoted`), obniżenie surowości (`demoted`) i odzyskania. Każde wejście w degradację zwiększa `bot_ui_performance_incidents_total{metric="...",severity="warning|critical"}` i inicjuje zestaw metryk czasowych (`bot_ui_performance_incident_active`, `bot_ui_performance_incident_age_seconds`, `bot_ui_performance_incident_started_at_seconds`, histogram `bot_ui_performance_incident_duration_seconds`). Warianty z etykietą `tag` działają równolegle do globalnych, a czyszczenie TTL tagów wygasza stany oraz zapisuje czas trwania ostatniego incydentu. Dzięki temu Prometheus przechowuje pełną historię przeciążeń CPU/GPU/RAM i skoków opóźnienia zdarzenie→klatka, a operator może korelować alerty z konkretnymi stanowiskami i długością degradacji.

Ścieżka alertowania czerpie z tych samych próbek. `UiTelemetryAlertSink` obserwuje progi ostrzegawcze i krytyczne dla opóźnienia zdarzenie→klatka oraz zużycia CPU/GPU/RAM – przekroczenia skutkują alertami `ui.performance.performance_metric` z kontekstem progu, tagu stanowiska i znacznikiem rozpoczęcia degradacji, a odzyskanie wysyła komunikat `info` wraz z czasem trwania incydentu. Wszystkie zdarzenia trafiają do `logs/ui_telemetry_alerts.jsonl`, co pozwala audytować okresy przeciążenia zasobów i korelować je z danymi Prometheusa.

Konfiguracja tych progów trafia do sekcji `runtime.metrics_service` w YAML. Pola `performance_alert_mode`, `performance_severity_*` oraz limity `performance_event_to_frame_*`, `cpu_utilization_*`, `gpu_utilization_*` i `ram_usage_*` umożliwiają zespołowi SRE dostrajanie alertów i logowania per środowisko – te same wartości wykorzystuje eksporter Prometheusa i warstwa alertów. Wpisanie `null` w którymkolwiek z progów całkowicie wyłącza obserwację danego zasobu, a ustawienie trybu `jsonl` pozwala jedynie logować zdarzenia bez wysyłania alertów. Dzięki temu pojedyncza konfiguracja YAML staje się źródłem prawdy dla surowości i czasu reakcji w całym łańcuchu telemetrii UI. Presety `python scripts/telemetry_risk_profiles.py` aktualizują te pola automatycznie dla profili `conservative`/`balanced`/`aggressive`, dzięki czemu CLI `run_metrics_service.py --ui-alerts-risk-profile` przenosi także progi wydajności i ich surowości.

Analogiczny mechanizm objął stan reduce-motion. `UiTelemetryPrometheusExporter` utrzymuje teraz `bot_ui_reduce_motion_incident_active`, `bot_ui_reduce_motion_incident_age_seconds`, `bot_ui_reduce_motion_incident_started_at_seconds` oraz histogram `bot_ui_reduce_motion_incident_duration_seconds`. Metryki dostępne są zarówno globalnie, jak i z etykietą `tag`, a ich stan wygaszamy automatycznie, gdy tag przestaje publikować heartbeat w ramach okna TTL – histogram zachowuje wówczas łączny czas ostatniego incydentu. Dashboard Prometheusa może dzięki temu prezentować częstotliwość i długość degradacji spowodowanych wymuszeniem reduce-motion na poszczególnych stanowiskach, a alerty JSONL mają dodatkowy kontekst tagu i czasu trwania ostatniego zdarzenia.

Na podobnych zasadach monitorujemy teraz długotrwałe przekroczenia budżetu nakładek. Eksporter dodaje `bot_ui_overlay_incident_active`, `bot_ui_overlay_incident_age_seconds`, `bot_ui_overlay_incident_started_at_seconds` oraz histogram `bot_ui_overlay_incident_duration_seconds`, zarówno globalnie jak i per tag. Stan incydentu jest wygaszany przy odzyskaniu budżetu lub po wygaśnięciu heartbeatów tagu, a histogram zachowuje czas ostatniej degradacji. Dodatkowo metryka `bot_ui_overlay_capacity_ratio` odzwierciedla bieżący udział wykorzystania limitu (active/allowed), a nowy zestaw `bot_ui_overlay_violation_state`, `bot_ui_overlay_excess` i licznik `bot_ui_overlay_incidents_total` pokazują jednoznacznie, czy budżet został przekroczony, o ile nakładek i ile razy wystąpiły incydenty. Histogram `bot_ui_overlay_capacity_ratio_overrun` pozwala natomiast ocenić skalę przekroczeń (ratio-1) i planować korekty jeszcze zanim uruchomią się ostrzeżenia. Po stronie alertów `UiTelemetryAlertSink` śledzi start i czas trwania incydentu, rejestruje powód wysyłki (inicjalizacja, wzrost różnicy, cooldown, eskalacja surowości) i zapisuje ISO8601 `overlay_incident_started_at` / `overlay_incident_recovered_at` w kontekście. Konfiguracja pozwala na re-alert po wzroście obciążenia (`overlay_incident_realert_delta`), wymuszenie przypomnienia po zadanym czasie (`overlay_incident_realert_cooldown_seconds`) oraz automatyczną eskalację do poziomu krytycznego po długotrwałej degradacji (`overlay_incident_critical_after_seconds`). Dzięki temu operator widzi jedną spójną linię czasu incydentu zarówno w alertach, jak i w dzienniku JSONL. Uzupełnia to licznik `bot_ui_overlay_severity_transitions_total{state="warning|critical|recovered",reason="..."}`, który zlicza wszystkie przejścia pomiędzy poziomami surowości (także odzyskanie po wygaśnięciu heartbeatu) i pozwala zestawić alerty z danymi Prometheusa.

Analogicznie śledzimy surowość incydentów janku. Wraz z metrykami aktywności (`bot_ui_jank_incident_active`, `bot_ui_jank_incident_age_seconds`, `bot_ui_jank_incident_started_at_seconds`, histogram `bot_ui_jank_incident_duration_seconds` i licznik `bot_ui_jank_incidents_total`) eksporter publikuje teraz `bot_ui_jank_severity_state{severity="warning|critical"}` oraz licznik `bot_ui_jank_severity_transitions_total{state="warning|critical|recovered",reason="..."}`. Stany utrzymywane są globalnie i per tag, dzięki czemu Prometheus odzwierciedla eskalacje spowodowane przekroczeniem progu milisekundowego, a powroty po okresie ciszy zapisują się z powodem `quiet`. Operator widzi więc jednocześnie przebieg incydentu, jego surowość i ewentualne eskalacje na poszczególnych stanowiskach.

Eksporter rozszerzono również o metryki surowości naruszeń budżetu: gauge `bot_ui_overlay_violation_severity_state{severity="warning|critical"}` pokazuje aktualny poziom alarmowy (globalnie i per tag), a licznik `bot_ui_overlay_incident_events_total{severity="..."}` zlicza przełączenia pomiędzy stanami ostrzeżeń. Prógi eskalacji można dostroić – domyślnie poziom `critical` aktywuje się przy różnicy dwóch nakładek, ale możliwe jest też ustawienie krytycznego czasu trwania (np. 10 s ciągłej degradacji), po którym eksporter automatycznie podbije surowość nawet przy mniejszym przekroczeniu limitu. Dzięki temu dashboard Prometheusa odzwierciedla tę samą logikę eskalacji, którą stosuje warstwa alertów.

`UiTelemetryAlertSink` wykorzystuje te dane do śledzenia długotrwałych incydentów reduce-motion. Po przekroczeniu konfigurowalnego progu czasu trwania wysyłany jest alert kategorii `ui.performance.reduce_motion_incident` wraz z informacją o długości degradacji, progu, tagu, liczbie okien i aktualnym FPS. Eskalacja do poziomu `critical` następuje automatycznie po osiągnięciu progów krytycznych, a ponowne ostrzeżenia respektują zarówno interwał (ile dodatkowego czasu upłynęło od poprzedniego alertu), jak i cooldown (minimum czasu pomiędzy kolejnymi powiadomieniami). Zakończenie incydentu generuje komunikat odzyskania z dokładnymi znacznikami rozpoczęcia i zakończenia, dzięki czemu dziennik JSONL oraz kanały eskalacji zawierają pełną linię czasu zdarzenia.

Alerty zostały rozbudowane także o monitorowanie bezczynnych tagów UI. `UiTelemetryAlertSink` śledzi monotoniczny zegar ostatniej próbki dla każdego tagu i po przekroczeniu okna `tag_inactivity_threshold_seconds` wysyła ostrzeżenie kategorii `ui.availability.tag_inactivity` wraz z informacją o czasie ostatniego snapshotu, momencie wejścia w stan degradacji oraz ostatnio znanym ekranie. Wznowienie telemetrii generuje komunikat odzyskania z czasem niedostępności, a oba zdarzenia trafiają do `logs/ui_telemetry_alerts.jsonl`, dzięki czemu operatorzy mają audytowalny ślad incydentów dostępnościowych bez konieczności przeszukiwania surowych logów aplikacji.
Telemetria UI została zintegrowana z eksporterem Prometheusa (`bot_core/observability/ui_metrics.py`) oraz rozszerzonym serwisem gRPC (`bot_core/runtime/metrics_service.py`). Każdy `MetricsSnapshot` aktualizuje metryki (`bot_ui_fps`, `bot_ui_overlay_active`, histogram janku itp.) i trafia do `UiTelemetryAlertSink`, który zapisuje zdarzenia w `logs/ui_telemetry_alerts.jsonl` oraz wysyła alerty przez `AlertRouter`. Eksporter promuje również kontekst ekranów – `bot_ui_screen_refresh_hz`, `bot_ui_screen_device_pixel_ratio` oraz `bot_ui_screen_resolution_px{dimension="width|height"}` – dzięki czemu dashboard Prometheus może korelować spadki FPS z konkretnymi konfiguracjami monitorów. Serwer metryk potrafi obsłużyć TLS/mTLS, weryfikuje tokeny RBAC (scope `metrics.write`) i udostępnia dane dla UI, Prometheusa oraz pipeline'ów operacyjnych. Dzięki temu panel administratorski może jednocześnie monitorować kondycję interfejsu i reagować na ostrzeżenia o spadku FPS lub przekroczeniu budżetu nakładek. Dodatkowo `UiTelemetryAlertSink` śledzi teraz stan bufora retry – gdy backlog przekroczy konfigurowalny próg pojawia się ostrzeżenie „retry backlog”, a powrót poniżej progu skutkuje alertem informacyjnym. Pozwala to operatorom wychwycić dłuższe braki łączności zanim zagrożą stabilności panelu.

Ścieżka raportowania została utwardzona po stronie klienta Qt. `UiTelemetryReporter` korzysta ze współdzielonego `MetricsClientInterface` i bufora ponowień, który przechowuje do 16 ostatnich próbek. Każde nowe zgłoszenie najpierw opróżnia kolejkę – w przypadku sukcesu zaległe rekordy są wysyłane w kolejności FIFO, a przy kolejnej awarii wiadomość pozostaje w buforze bez blokowania wątku UI. Bufor ma limit pojemności, a jego przepełnienie generuje ostrzeżenie w logach i usuwa najstarszą próbkę, co pozwala utrzymać stabilny przepływ nawet podczas dłuższych przerw w dostępności serwisu gRPC. Stan kolejki jest publikowany do warstwy QML (`Application.telemetryPendingRetryCount`) i eksponowany w stopce aplikacji, a dodatkowo każda udana próbka przekazuje do Prometheusa metrykę `bot_ui_retry_backlog{phase="before_flush|after_flush"}`, co pozwala operatorom korelować okna offline z późniejszymi flushami i ocenić, czy bufor nie przekracza przyjętych progów. Sam sink alertów ponownie emituje ostrzeżenia, kiedy backlog wzrośnie o konfigurowalny krok, po przekroczeniu konfigurowalnego progu krytycznego automatycznie eskaluje je do poziomu `critical`, a dodatkowo respektuje zdefiniowany cooldown re-alertów, aby uniknąć zalewania kanałów ostrzeżeniami w trakcie dłuższych incydentów. W środowiskach o wolnym łączu można również skonfigurować eskalację „czasową” – jeśli backlog utrzymuje się powyżej progu przez określoną liczbę sekund, alert przechodzi w stan `critical`, a w kontekście i logach pojawia się informacja o czasie trwania degradacji, wraz z dokładnym znacznikiem rozpoczęcia i zakończenia incydentu.

## Mechanizmy bezpieczeństwa i compliance

- **Wymuszenie trybu demo/paper:** `StrategyContext.require_demo_mode` oraz walidacja konfiguracji w runtime zapobiegają uruchomieniu strategii live bez akceptacji ryzyka.
- **Separacja uprawnień:** adaptery giełdowe stosują osobne klucze API dla `read`/`trade`, konfiguracja środowisk wymaga explicite zdefiniowanych `required_permissions` i `forbidden_permissions`, a `SecretManager` pilnuje środowisk, rotacji kluczy i blokuje start, gdy klucz posiada niewłaściwe uprawnienia.
- **Kontrola ryzyka:** `RiskEngine` blokuje sygnały przekraczające limity ekspozycji, liczbę pozycji, dzienny drawdown i wymagania margin.
- **Alerty i audyt:** `AlertRouter` utrzymuje kanały eskalacji, logi audytowe, throttling powiadomień oraz politykę retencji (24 miesiące).
- **Zgłaszanie incydentów:** każde naruszenie bezpieczeństwa lub anomalia handlowa musi być zgłoszona do zespołu bezpieczeństwa (`#sec-alerts`) i opisana w raporcie post-incident w ciągu 24h. Dzienniki danych i alertów są zabezpieczane do analizy.

## Spójność z dokumentacją etapu 1

Dokument został zaktualizowany zgodnie z zakresem `docs/architecture/phase1_foundation.md`. Najważniejsze założenia – modularny podział `bot_core`, separacja środowisk, profile ryzyka, centralny bootstrap oraz audyt alertów – są odzwierciedlone w powyższych sekcjach. Zalecane jest cykliczne review z zespołem architektury po każdej istotnej zmianie modułów.

## Materiały onboardingowe

`docs/ARCHITECTURE.md` dodajemy do listy materiałów startowych dla nowych członków zespołu (obok `docs/architecture/phase1_foundation.md` i checklist bezpieczeństwa). Dokument stanowi punkt wejścia do zrozumienia przepływu demo → paper → live oraz powiązanych mechanizmów ochronnych.

## Kolejne kroki

- Rozbudowa dokumentacji o diagramy przepływu danych i interakcji pomiędzy modułami.
- Dodanie testów integracyjnych pipeline'u (sygnał → ryzyko → egzekucja) z wykorzystaniem środowisk demo i paper.
- Przygotowanie checklisty audytu LIVE (compliance + ryzyko technologiczne) wraz z kryteriami przejścia do produkcji.
