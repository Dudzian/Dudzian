# Playbook wsparcia L1/L2 – Stage5 Compliance & Cost Control

## Cel
Zapewnić zespołom dyżurnym powtarzalny proces obsługi środowiska Stage5 – w szczególności monitorowanie kosztów transakcyjnych, decyzji orchestratora oraz rotacji kluczy – od wstępnej obserwacji (L1) po działania naprawcze i audyt (L2).

## Zakres odpowiedzialności
- **L1 (NOC/monitoring)** – monitorowanie alertów SLO (koszt, fill rate, decision latency), dashboardu Grafany *Stage5 – Compliance & Cost Control* oraz wyników automatycznych dry-runów OEM.
- **L2 (Ops/Engineering)** – analiza DecisionOrchestrator, modułu TCO, integracji z risk engine oraz procesów rotacji kluczy; przygotowanie działań naprawczych i komunikacja z właścicielami strategii.

## Checklista L1
| Krok | Odpowiedzialny | Artefakty | Akceptacja |
| --- | --- | --- | --- |
| 1. Potwierdź alert w Alertmanagerze (`stage5_tco_cost_spike`, `stage5_decision_latency`, `stage5_fill_rate_drop`). | L1 | Log Alertmanagera, wpis w kanale on-call | Alert oznaczony jako `acknowledged`; ID incydentu zapisane |
| 2. Sprawdź dashboard *Stage5 – Compliance & Cost Control* (panele `avg_cost_per_trade`, `slippage_bps`, `decision_latency_ms`, `slo_breach_count`). | L1 | Zrzut panelu, komentarz w decision logu | Wartości w zielonym/żółtym zakresie lub eskalacja do L2 |
| 3. Uruchom `python scripts/audit_stage4_compliance.py --profile stage5 --mtls-bundle-name core-oem` w trybie odczytu. | L1 | Raport JSON w `var/audit/acceptance/<TS>/stage5_support/` | Status `pass` lub ostrzeżenia przekazane do L2 |
| 4. Zweryfikuj ostatni wpis `run_oem_acceptance.py` – sekcja TCO i rotacji kluczy (`var/audit/acceptance/<TS>/meta.json`). | L1 | Plik meta, decyzja HMAC | Raport oznaczony jako aktualny (<7 dni) |
| 5. Jeśli alert utrzymuje się >5 min lub audyt zgłasza `fail`, eskaluj do L2. | L1 | Kanał eskalacji wg `ops/oncall_rotation.yaml` | Eskalacja potwierdzona przez L2 |

## Checklista L2
| Krok | Odpowiedzialny | Artefakty | Akceptacja |
| --- | --- | --- | --- |
| 1. Uruchom `python scripts/run_tco_analysis.py --output var/audit/tco/<TS>/incident.csv` i porównaj z progiem w `config/core.yaml`. | L2 | Raport CSV/PDF, podpis HMAC | Koszt poniżej progu lub decyzja o ograniczeniu strategii |
| 2. Wykonaj `python scripts/run_decision_engine_smoke.py --mode live --risk-snapshot <ścieżka> --candidates <ścieżka> --tco-report <ścieżka> --output <ścieżka>` dla strategii objętej alertem (w trybie testowym możesz użyć `--mode paper`, który korzysta z danych referencyjnych). | L2 | Log CLI, podpis `smoke.sig` | Status `success`; w razie `fail` przygotuj plan rollbacku |
| 3. Zweryfikuj rotację kluczy: `python scripts/rotate_keys.py --status --bundle core-oem` (możesz użyć skrótu `--status core-oem` lub `status core-oem`). | L2 | Raport JSON, wpis decision logu | Brak przeterminowanych kluczy; w przeciwnym razie zaplanuj rotację |
| 4. Uaktualnij decision log (`verify_decision_log.py summary --category stage5_incident`) i potwierdź obecność pól TCO. | L2 | Raport w `var/audit/decisions/` | Wpis zawiera `tco_kpi`, `decision_path`, `rotation_event_id` |
| 5. Jeśli konieczne, uruchom `python scripts/disable_multi_strategy.py --component decision_orchestrator --reason <ID>` zgodnie z runbookiem rollbacku. | L2 | `var/runtime/overrides/decision_orchestrator_disable.json`, wpis logu | Orchestrator w oczekiwanym stanie, plan przywrócenia przygotowany |
| 6. Po incydencie zaktualizuj dokumentację (`docs/runbooks/STAGE5_SUPPORT_PLAYBOOK.md`, `docs/runbooks/STAGE5_COMPLIANCE_CHECKLIST.md`) i przekaż lessons learned zespołowi compliance. | L2 | Commit, wpis w change-logu | Review zatwierdzone przez właściciela produktu |
| 7. Jeżeli incydent wymagał warsztatu ad-hoc (lessons learned), zarejestruj go przy pomocy `python scripts/log_stage5_training.py` i załącz artefakty (nagranie, slajdy) do `var/audit/training/<data>/`. | L2 | `var/audit/training/stage5_training_log.jsonl`, wpis decision log `stage5_training` | Wpis podpisany HMAC, artefakty dostępne offline |

> Raport `--status` zawiera sekcję `summary` z liczbą wpisów `ok/warning/due/overdue`
> oraz listę `entries` z polami `state`, `days_since_rotation`, `due_in_days` i
> `last_rotated`. Dzięki temu operatorzy L2 mogą natychmiast potwierdzić, czy
> bundel (np. `core-oem`) wymaga akcji, oraz dołączyć wynik do decision logu bez
> dodatkowych narzędzi.

## Walidacja modeli Decision Engine
- Uruchom pipeline treningowy: `python -m bot_core.ai.pipeline training.csv models/decision autotrader target --features close volume --register --config config/decision_engine.yaml`. Upewnij się, że artefakt zawiera metadane (`trained_at`, `metrics.mae`, `metadata.feature_scalers`).
- Zarejestruj wygenerowany model w DecisionOrchestratorze (w logach pojawi się wpis „Registered model autotrader”). Sprawdź w `var/runtime/decision_orchestrator.json`, że `model_selection` odnotowuje nową wersję.
- W `config/core.yaml` ustaw `decision_engine.evaluation_history_limit` adekwatnie do potrzeb audytu (domyślnie 512 wpisów). Limit chroni pamięć runtime i determinuje, ile ostatnich ewaluacji będzie widocznych w DecisionAwareSignalSink i UI.
- Wyeksportuj bieżące podsumowanie jakości: `python scripts/export_decision_engine_summary.py --ledger <ledger_dir> --output var/audit/decision_engine/<TS>/summary.json --environment <env> --portfolio <portfolio> --include-history`. Artefakt dołącz do raportu hypercare Stage5 i zweryfikuj, że `total`, `acceptance_rate` oraz `latest_model` spełniają polityki.
- W UI/CLI Stage5 sprawdź sekcję `decision_engine_summary` (całkowita liczba ewaluacji, acceptance rate, ostatni model i snapshot progów). Raport zawiera również `model_usage`, `risk_flag_counts`, `stress_failure_counts` oraz `latest_status`, a od teraz także `history_start_generated_at`, `full_total/full_acceptance_rate`, statystyki opisowe `median_*`, `p90_*`, `p95_*` dla kosztów/edge/latency oraz rozkłady `action_usage`, `strategy_usage`, `symbol_usage`. Monitoruj nowe liczniki dywersyfikacji (`unique_rejection_reasons`, `unique_risk_flags`, `unique_models`, `unique_actions`, `unique_strategies`, `unique_symbols`) oraz odpowiadające im pola `models_with_accepts`, `actions_with_accepts`, `strategies_with_accepts`, `symbols_with_accepts`, aby potwierdzić, że aktywne sygnały pochodzą z wielu źródeł i faktycznie przechodzą przez orkiestrator. Nowe sekcje `*_breakdown` prezentują akceptacje, odrzucenia i współczynnik sukcesu per model/akcja/strategia/symbol i są wymagane do audytu skuteczności, a dodatkowe `risk_flag_breakdown` oraz `stress_failure_breakdown` pokazują jak często sygnały z ostrzeżeniami przechodzą przez orkiestrator. Dodane pola `longest_acceptance_streak`, `longest_rejection_streak`, `current_acceptance_streak` oraz `current_rejection_streak` pozwalają natychmiast ocenić trend przyjęć/odrzuceń i wychwycić degradacje modeli. W najnowszej wersji raport zawiera również `avg_expected_value_bps`, `median_expected_value_bps`, `avg_model_expected_value_bps`, `median_model_expected_value_bps` oraz `latest_expected_value_bps/latest_model_expected_value_bps`, co pozwala na weryfikację realnego value-add modeli względem progów kosztowych. Zrzut obejmuje także bieżące wartości `latest_net_edge_bps`, `latest_cost_bps`, `latest_latency_ms`, `latest_expected_probability`, `latest_expected_return_bps`, `latest_notional` oraz odpowiadające im metryki modelowe (`latest_model_expected_return_bps`, `latest_model_success_probability`), aby operator mógł natychmiast zweryfikować świeży sygnał pod kątem kosztów i wielkości. Dodatkowe pola `avg_expected_value_minus_cost_bps`, `median_expected_value_minus_cost_bps`, `avg_model_expected_value_minus_cost_bps`, `median_model_expected_value_minus_cost_bps` oraz odpowiadające im `latest_*` pozwalają kontrolować profitability po odjęciu kosztów transakcyjnych. Najnowsza iteracja agregacji dodaje `std_*` dla kluczowych metryk (np. `std_expected_value_bps`, `std_expected_value_minus_cost_bps`, `std_model_expected_value_minus_cost_bps`, `std_cost_bps`), dzięki czemu audyt może ocenić zmienność wyników modeli. Raport prezentuje również sumaryczne pola `sum_net_edge_bps`, `sum_cost_bps`, `sum_expected_return_bps`, `sum_expected_value_bps`, `sum_expected_value_minus_cost_bps`, `sum_model_expected_return_bps`, `sum_model_expected_value_bps`, `sum_model_expected_value_minus_cost_bps` oraz `sum_latency_ms`/`sum_notional`, które ułatwiają oszacowanie łącznego wkładu decyzji i kosztów w analizowanym oknie audytu. Nowo dodane pola `accepted_*`/`rejected_*` (np. `accepted_avg_net_edge_bps`, `rejected_sum_expected_value_minus_cost_bps`, `accepted_model_expected_value_minus_cost_bps_count`) pokazują rozbicie kluczowych metryk na zaakceptowane i odrzucone decyzje, dzięki czemu hypercare może szybko ocenić czy edge, koszty, EV i wolumeny są generowane przez sygnały dopuszczone do rynku. Te dane pozwalają szybko ocenić jakość decyzji AI, trendy czasowe i zachowanie modeli w audycie hypercare. Dane pochodzą z `DecisionAwareSignalSink.evaluation_summary()`.
  *NOWOŚĆ:* każda sekcja `*_breakdown` zawiera teraz podklucz `metrics` z agregatami (`total_sum`, `accepted_sum`, `rejected_sum`, średnie i liczności) dla net edge, kosztów, expected value (brutto/netto), latency oraz notional, dzięki czemu audyt hypercare może natychmiast wskazać, które modele/akcje/strategie/symbole generują największy edge po kosztach i które są źródłem odrzuceń.
- Segmentowe statystyki `accepted_median_*`/`accepted_p10_*`/`accepted_p90_*`/`accepted_std_*` (oraz analogiczne `rejected_*`) rozszerzają te rozbicia o mediany, kwantyle i zmienność dla edge, kosztów, prawdopodobieństw, EV, EV minus kosztów, notionale, latencji i metryk modelowych – audyt Stage5 powinien potwierdzić, że zaakceptowane sygnały mają komfortowe marginesy i stabilną jakość w porównaniu z odrzuconymi.
- Dodatkowo monitoruj pola `*_threshold_margin`, `*_threshold_breaches` i `latest_*_threshold_margin` – wskazują one zapas względem progów orchestratora i sygnalizują, które kandydatury balansują na granicy minimalnych prawdopodobieństw lub maksymalnych kosztów/latencji/notionalu.
- Nowe metryki `accepted_*_threshold_margin` oraz `rejected_*_threshold_margin` (wraz z `min/median/p10/p90/std`) pokazują, jak blisko progów znajdują się przyjęte i odrzucone sygnały – wykorzystaj je do szybkiej oceny, czy orkiestrator wpuszcza kandydatury z komfortowym zapasem, czy raczej działa na granicy limitów.
- W UI/CLI Stage5 sprawdź sekcję `decision_engine_summary` (całkowita liczba ewaluacji, acceptance rate, ostatni model i snapshot progów). Dane pochodzą z `DecisionAwareSignalSink.evaluation_summary()` i pozwalają szybko ocenić jakość decyzji AI oraz najczęstsze powody odrzuceń.
- Przed startem AutoTradera potwierdź, że GUI widzi `decision_engine.accepted == True` w ostatnim `RiskDecision`. W trybie live każda decyzja z flagą `ai_degraded` musi zostać ręcznie zatwierdzona (menedżer modeli powinien zgłosić ostrzeżenie „AI backend degraded”).

## Procedura eskalacji
1. **Warunki eskalacji do Incident Managera:** `avg_cost_per_trade` > 2× progu, `decision_latency_ms` > 500 ms p95 przez >10 min, brak raportu rotacji kluczy > 30 dni, status `fail` w `audit_stage4_compliance --profile stage5`.
2. **Kanały:** Slack `#ops-stage5`, telefon dyżurny (`ops/oncall_rotation.yaml`), rezerwowy most konferencyjny.
3. **Komunikacja z OEM:** przygotuj komunikat według wzoru w `docs/runbooks/operations/strategy_incident_playbook.md`, uwzględniając wpływ kosztów i decyzji.

## Artefakty / Akceptacja
- Raporty TCO, decision engine smoke, rotacji kluczy i audytu compliance zapisane w `var/audit/acceptance/<timestamp>/stage5_support/`.
- Wpis decision logu `audit/decision_logs/runtime.jsonl` z kategorią `stage5_incident`, podpisany HMAC i zweryfikowany `verify_decision_log.py`.
- Aktualny eksport dashboardu i alertów (JSON + sygnatura) dołączony do incydentu.
- Lista obecności warsztatu Stage5 oraz aktualizacja dokumentacji po incydencie.
